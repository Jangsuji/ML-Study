{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Features_practice.ipynb","provenance":[],"authorship_tag":"ABX9TyNW7hZws42X0TcRJrQ5DBc8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Image features exercise"],"metadata":{"id":"zXeAy5xNjCQn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"swbUM0eQi2AC"},"outputs":[],"source":["# Use the validation set to tune the learning rate and regularization strength\n","\n","from cs231n.classifiers.linear_classifier import LinearSVM\n","\n","learning_rates = [1e-9, 1e-8, 1e-7]\n","regularization_strengths = [5e4, 5e5, 5e6]\n","\n","results = {}\n","best_val = -1\n","best_svm = None\n","\n","################################################################################\n","# TODO:                                                                        #\n","# Use the validation set to set the learning rate and regularization strength. #\n","# This should be identical to the validation that you did for the SVM; save    #\n","# the best trained classifer in best_svm. You might also want to play          #\n","# with different numbers of bins in the color histogram. If you are careful    #\n","# you should be able to get accuracy of near 0.44 on the validation set.       #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","for lr in learning_rates:\n","    for reg in regularization_strengths:\n","        svm = LinearSVM()\n","        svm.train(X_train_feats, y_train, lr, reg,\n","                              num_iters=800, verbose=True)\n","        acc_val = np.mean(y_val == svm.predict(X_val_feats))\n","        acc_train = np.mean(y_train == svm.predict(X_train_feats))\n","\n","        results[(lr,reg)]= (acc_train, acc_val)\n","\n","        if acc_val > best_val:\n","          best_val = acc_val\n","          best_svm = svm\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","# Print out results.\n","for lr, reg in sorted(results):\n","    train_accuracy, val_accuracy = results[(lr, reg)]\n","    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n","                lr, reg, train_accuracy, val_accuracy))\n","    \n","print('best validation accuracy achieved: %f' % best_val)"]},{"cell_type":"code","source":["from cs231n.classifiers.fc_net import TwoLayerNet\n","from cs231n.solver import Solver\n","\n","input_dim = X_train_feats.shape[1]\n","hidden_dim = 500\n","num_classes = 10\n","\n","net = TwoLayerNet(input_dim, hidden_dim, num_classes)\n","best_net = None\n","\n","################################################################################\n","# TODO: Train a two-layer neural network on image features. You may want to    #\n","# cross-validate various parameters as in previous sections. Store your best   #\n","# model in the best_net variable.                                              #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","\n","results = {}\n","best_val = -1\n","\n","data = {}\n","data[\"X_train\"] = X_train_feats\n","data[\"y_train\"] = y_train\n","data[\"X_val\"] = X_val_feats\n","data[\"y_val\"] = y_val\n","data[\"X_test\"] = X_test_feats\n","data[\"y_test\"] = y_test\n","\n","\n","\n","solver = Solver(net, data,\n","                update_rule='sgd',\n","                optim_config={\n","                  'learning_rate': 0.5,\n","                },\n","                lr_decay=0.95,\n","                num_epochs=10, batch_size=100,\n","                print_every=100)\n","solver.train()\n","best_val = solver.best_val_acc\n","best_net = net\n","    \n","print('best validation accuracy achieved: %f' % best_val)\n","\n","# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"],"metadata":{"id":"zU0K2t9qjH8A"},"execution_count":null,"outputs":[]}]}